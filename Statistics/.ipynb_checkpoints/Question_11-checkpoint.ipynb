{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ca86c8",
   "metadata": {},
   "source": [
    "### Q-11. Given the data of a feature contributing to different classes                \n",
    "data - https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\n",
    "\n",
    "a. Check whether the distribution of all the classes are the same or not.                   \n",
    "b. Check for the equality of variance/                                \n",
    "c. Which amount LDA and QDA would perform better on this data for classification and why.                    \n",
    "d. Check the equality of mean for between all the classes.      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5f2d9",
   "metadata": {},
   "source": [
    "**Ans:-**\n",
    "#### a. Checking the distribution of all the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfb1fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of classes is not the same.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Extracting the blood pressure before and after values\n",
    "bp_before = [130, 142, 120, 135, 148, 122, 137, 130, 142, 128, 135, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135, 131, 127, 130, 142, 128, 136, 140, 132, 145, 124, 128, 136, 143, 127, 139, 135]\n",
    "bp_after = [120, 135, 118, 127, 140, 118, 129, 124, 137, 125, 129, 132, 125, 136, 118, 122, 130, 139, 123, 132, 131, 126, 120, 123, 139, 122, 129, 136, 127, 140, 119, 121, 129, 137, 122, 135, 129, 124, 119, 124, 139, 123, 131, 135, 130, 125, 121, 124, 122, 129, 141, 118, 121, 129, 137, 123, 135, 130, 125, 121, 124, 124, 123, 119, 124, 139, 123, 131, 135, 130, 125, 121, 124, 122, 129, 141, 118, 121, 129, 137, 123, 135, 130, 125, 121, 124, 124, 123, 119, 124, 139, 123, 131, 135, 130, 125, 121, 124, 122, 129, 141, 118, 121, 129, 137, 123, 135, 130, 125, 121, 124, 124, 123, 119, 124, 139, 123, 131, 135, 130, 125, 121]\n",
    "\n",
    "# Perform one-way ANOVA test\n",
    "_, p_value = stats.f_oneway(bp_before, bp_after)\n",
    "\n",
    "# Check the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"The distribution of classes is not the same.\")\n",
    "else:\n",
    "    print(\"The distribution of classes is the same.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86883f05",
   "metadata": {},
   "source": [
    "#### b. Checking the equality of variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba908be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variances are equal.\n"
     ]
    }
   ],
   "source": [
    "# Perform Levene's test for equality of variances\n",
    "_, p_value = stats.levene(bp_before, bp_after)\n",
    "\n",
    "# Check the p-value\n",
    "if p_value > 0.05:\n",
    "    print(\"The variances are equal.\")\n",
    "else:\n",
    "    print(\"The variances are not equal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86476609",
   "metadata": {},
   "source": [
    "#### c. Determining which algorithm (LDA or QDA) would perform better for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741769e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both LDA and QDA perform equally well for classification.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Creating the feature matrix and target variable\n",
    "X = np.array([[130, 120], [142, 135], [120, 118], [135, 127], [148, 140], [122, 118], [137, 129], [130, 124], [142, 137],\n",
    "              [128, 125], [135, 129], [140, 132], [132, 125], [145, 136], [124, 118], [128, 122], [136, 130],\n",
    "              [143, 139], [127, 123], [139, 132], [135, 131], [131, 126], [127, 120], [130, 123], [142, 139],\n",
    "              [128, 122], [136, 129], [140, 136], [132, 127], [145, 140], [124, 119], [128, 121], [136, 129],\n",
    "              [143, 137], [127, 122], [139, 135], [135, 129], [131, 124], [127, 119], [130, 124], [142, 139],\n",
    "              [128, 123], [136, 131], [140, 135], [132, 127], [145, 141], [124, 118], [128, 121], [136, 129],\n",
    "              [143, 137], [127, 123], [139, 135], [135, 130], [131, 125], [127, 121], [130, 124], [142, 139],\n",
    "              [128, 123], [136, 131], [140, 136], [132, 127], [145, 141], [124, 118], [128, 121], [136, 129],\n",
    "              [143, 137], [127, 123], [139, 135], [135, 130], [131, 125], [127, 121], [130, 124], [128, 122],\n",
    "              [136, 129], [140, 135], [132, 127], [145, 141], [124, 118], [128, 121], [136, 129], [143, 137],\n",
    "              [127, 123], [139, 135], [135, 130], [131, 125], [127, 121], [130, 124], [142, 139], [128, 123],\n",
    "              [136, 131], [140, 136], [132, 127], [145, 141], [124, 118], [128, 121], [136, 129], [143, 137],\n",
    "              [127, 123], [139, 135], [135, 130]])\n",
    "\n",
    "y = np.array([0] * 50 + [1] * 50)\n",
    "\n",
    "# Creating and fitting the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_scores = cross_val_score(lda, X, y, cv=5)  # 5-fold cross-validation\n",
    "lda_accuracy = np.mean(lda_scores)\n",
    "\n",
    "# Creating and fitting the QDA model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda_scores = cross_val_score(qda, X, y, cv=5)  # 5-fold cross-validation\n",
    "qda_accuracy = np.mean(qda_scores)\n",
    "\n",
    "# Comparing the accuracies\n",
    "if lda_accuracy > qda_accuracy:\n",
    "    print(\"LDA performs better for classification.\")\n",
    "elif lda_accuracy < qda_accuracy:\n",
    "    print(\"QDA performs better for classification.\")\n",
    "else:\n",
    "    print(\"Both LDA and QDA perform equally well for classification.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496dbcf5",
   "metadata": {},
   "source": [
    "#### d. Checking the equality of mean between all the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9b8c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are significant differences in the means of the classes.\n"
     ]
    }
   ],
   "source": [
    "# Perform one-way ANOVA test\n",
    "_, p_value = stats.f_oneway(bp_before, bp_after)\n",
    "\n",
    "# Check the p-value\n",
    "if p_value < 0.05:\n",
    "    print(\"There are significant differences in the means of the classes.\")\n",
    "else:\n",
    "    print(\"The means of the classes are equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc7d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
